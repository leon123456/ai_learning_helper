# app/services/aliyun_paper_cut.py

"""
é˜¿é‡Œäº‘è¯•å·åˆ‡é¢˜è¯†åˆ« OCR æœåŠ¡
API: RecognizeEduPaperCutï¼ˆè¯•å·åˆ‡é¢˜è¯†åˆ«ï¼‰
å‚è€ƒæ–‡æ¡£: https://help.aliyun.com/zh/ocr/developer-reference/api-ocr-api-2021-07-07-recognizeedupapercut

åŠŸèƒ½ç‰¹ç‚¹ï¼š
- è‡ªåŠ¨åˆ‡é¢˜ï¼ˆé¢˜å·è¯†åˆ«å‡†ç¡®ï¼‰
- æ¯ä¸ªè¯å•ç‹¬è¯†åˆ«ï¼ŒåŒ…å«åæ ‡å’Œåˆ†ç±»ä¿¡æ¯
- æ”¯æŒæ•°å­¦å…¬å¼ OCRï¼ˆrecClassify=51 è¡¨ç¤ºå…¬å¼ï¼ŒLaTeX æ ¼å¼ï¼‰
- è¿”å›å®Œæ•´çš„é¢˜ç›®æ–‡æœ¬ï¼ˆtext å­—æ®µï¼‰
- é€‚ç”¨æ•´é¡µè¯•å·ã€æ‹ç…§å›¾ç‰‡

ä¸ RecognizeEduPaperStructed çš„åŒºåˆ«ï¼š
- PaperCut: è¿”å› page_list ç»“æ„ï¼ŒæŒ‰é¡µé¢ç»„ç»‡ï¼Œè¯çº§åˆ«è¯†åˆ«
- PaperStructed: è¿”å› part_info ç»“æ„ï¼ŒæŒ‰å¤§é¢˜åˆ†ç±»ï¼Œå…ƒç´ çº§åˆ«è¯†åˆ«ï¼ˆé¢˜å¹²ã€é€‰é¡¹åˆ†å¼€ï¼‰
"""

import json
import re
from typing import Optional, List, Dict, Any
from app.core.config import settings


class AliyunPaperCutClient:
    """é˜¿é‡Œäº‘è¯•å·åˆ‡é¢˜è¯†åˆ«å®¢æˆ·ç«¯"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–é˜¿é‡Œäº‘ OCR å®¢æˆ·ç«¯
        
        å‡­æ®é…ç½®ï¼š
        - .env ä¸­çš„ ALIYUN_ACCESS_KEY_ID å’Œ ALIYUN_ACCESS_KEY_SECRET
        """
        self.endpoint = settings.ALIYUN_OCR_ENDPOINT
        self.access_key_id = settings.ALIYUN_ACCESS_KEY_ID
        self.access_key_secret = settings.ALIYUN_ACCESS_KEY_SECRET
        
        if not self.access_key_id or not self.access_key_secret:
            raise ValueError(
                "é˜¿é‡Œäº‘ OCR é…ç½®ä¸å®Œæ•´ã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ï¼š\n"
                "  ALIYUN_ACCESS_KEY_ID=ä½ çš„AccessKeyId\n"
                "  ALIYUN_ACCESS_KEY_SECRET=ä½ çš„AccessKeySecret\n"
            )
        
        print(f"âœ… ä½¿ç”¨é˜¿é‡Œäº‘ AccessKeyï¼ˆID: {self.access_key_id[:8]}...ï¼‰")
    
    async def recognize_paper_cut(
        self,
        image_url: Optional[str] = None,
        image_base64: Optional[str] = None,
        cut_type: str = "question",
        image_type: str = "scan",
        subject: str = "Math",
    ) -> Dict[str, Any]:
        """
        è¯†åˆ«è¯•å·å¹¶åˆ‡é¢˜
        
        Args:
            image_url: å›¾ç‰‡ URLï¼ˆå…¬ç½‘å¯è®¿é—®ï¼‰
            image_base64: å›¾ç‰‡ base64 ç¼–ç ï¼ˆä¸å«å‰ç¼€ï¼‰
            cut_type: åˆ‡é¢˜ç±»å‹ï¼Œquestion(åˆ‡é¢˜) / answer(åˆ‡ç­”æ¡ˆ)
            image_type: å›¾ç‰‡ç±»å‹ï¼Œscan(æ‰«æä»¶) / photo(å®æ‹å›¾)
            subject: å­¦ç§‘ç±»å‹ï¼ŒMath/Chinese/English/Physics ç­‰
        
        Returns:
            åŸå§‹ API å“åº”æ•°æ®ï¼ŒåŒ…å« page_list ç»“æ„ï¼š
            {
                "page_list": [
                    {
                        "page_id": é¡µç ,
                        "width": å›¾ç‰‡å®½åº¦,
                        "height": å›¾ç‰‡é«˜åº¦,
                        "subject_list": [
                            {
                                "ids": ["1"],  # é¢˜å·
                                "text": "å®Œæ•´é¢˜ç›®æ–‡æœ¬",
                                "content_list_info": [...],  # é¢˜ç›®åŒºåŸŸåæ ‡
                                "prism_wordsInfo": [...]     # è¯çº§åˆ«ä¿¡æ¯
                            }
                        ]
                    }
                ]
            }
        """
        from alibabacloud_ocr_api20210707.client import Client as OcrApiClient
        from alibabacloud_tea_openapi import models as open_api_models
        from alibabacloud_ocr_api20210707 import models as ocr_api_20210707_models
        from alibabacloud_tea_util import models as util_models
        
        # åˆ›å»ºå®¢æˆ·ç«¯é…ç½®
        config = open_api_models.Config(
            access_key_id=self.access_key_id,
            access_key_secret=self.access_key_secret,
        )
        
        # è®¾ç½® endpoint
        if self.endpoint.startswith('ocr-api.'):
            config.endpoint = self.endpoint
        else:
            config.endpoint = f'ocr-api.{self.endpoint}'
        
        client = OcrApiClient(config)
        
        # å‡†å¤‡è¯·æ±‚å‚æ•°
        request = ocr_api_20210707_models.RecognizeEduPaperCutRequest()
        
        if image_url:
            # ä½¿ç”¨å›¾ç‰‡ URL
            request.url = image_url
            print(f"  âœ“ ä½¿ç”¨ URL æ–¹å¼: {image_url[:80]}...")
        elif image_base64:
            # ä½¿ç”¨ base64 ç¼–ç çš„å›¾ç‰‡
            # å¦‚æœåŒ…å«å‰ç¼€ï¼Œå»æ‰
            if image_base64.startswith("data:image"):
                image_base64 = image_base64.split(",")[1]
            
            # body å­—æ®µéœ€è¦çš„æ˜¯å›¾ç‰‡çš„åŸå§‹äºŒè¿›åˆ¶æ•°æ®
            import base64 as b64
            image_bytes = b64.b64decode(image_base64)
            request.body = image_bytes
            
            print(f"  âœ“ ä½¿ç”¨ body æ–¹å¼")
            print(f"    - äºŒè¿›åˆ¶å¤§å°: {len(image_bytes)} å­—èŠ‚ ({len(image_bytes)/1024:.2f} KB)")
        else:
            raise ValueError("å¿…é¡»æä¾› image_url æˆ– image_base64")
        
        # è®¾ç½®å¿…éœ€å‚æ•°
        request.cut_type = cut_type      # question / answer
        request.image_type = image_type  # scan / photoï¼ˆå¿…éœ€ï¼ï¼‰
        request.subject = subject        # å­¦ç§‘ç±»å‹
        
        print(f"  âœ“ cut_type: {cut_type}")
        print(f"  âœ“ image_type: {image_type}")
        print(f"  âœ“ subject: {subject}")
        
        try:
            # è°ƒç”¨ APIï¼ˆå¼‚æ­¥ï¼‰ï¼Œè®¾ç½®æ›´é•¿çš„è¶…æ—¶å’Œé‡è¯•
            runtime = util_models.RuntimeOptions(
                read_timeout=180000,   # è¯»å–è¶…æ—¶ 180 ç§’
                connect_timeout=60000, # è¿æ¥è¶…æ—¶ 60 ç§’
                autoretry=True,        # å¯ç”¨è‡ªåŠ¨é‡è¯•
                max_attempts=3,        # æœ€å¤šé‡è¯• 3 æ¬¡
            )
            
            response = await client.recognize_edu_paper_cut_with_options_async(request, runtime)
            
            # è§£æå“åº”
            if not response or not response.body:
                raise Exception("é˜¿é‡Œäº‘è¯•å·åˆ‡é¢˜è¯†åˆ« API è¿”å›ç©ºå“åº”")
            
            # è§£æè¿”å›çš„ JSON å­—ç¬¦ä¸²
            data_str = response.body.data
            if not data_str:
                raise Exception("é˜¿é‡Œäº‘è¯•å·åˆ‡é¢˜è¯†åˆ« API è¿”å›çš„ data ä¸ºç©º")
            
            data = json.loads(data_str)
            
            # ç»Ÿè®¡ä¿¡æ¯
            page_count = len(data.get("page_list", []))
            total_questions = sum(
                len(page.get("subject_list", []))
                for page in data.get("page_list", [])
            )
            
            print(f"âœ… è¯•å·åˆ‡é¢˜è¯†åˆ«æˆåŠŸ")
            print(f"   - é¡µé¢æ•°é‡: {page_count}")
            print(f"   - é¢˜ç›®æ€»æ•°: {total_questions}")
            
            return data
            
        except ImportError as e:
            raise ImportError(
                f"é˜¿é‡Œäº‘ OCR SDK æœªå®‰è£…ã€‚è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n"
                f"pip install alibabacloud-ocr-api20210707 alibabacloud-tea-openapi "
                f"alibabacloud-tea-util alibabacloud-credentials\n"
                f"åŸå§‹é”™è¯¯: {e}"
            )
        except Exception as e:
            error_msg = str(e)
            if hasattr(e, 'message'):
                error_msg = e.message
            if hasattr(e, 'data') and e.data:
                recommend = e.data.get("Recommend", "")
                if recommend:
                    error_msg += f" è¯Šæ–­åœ°å€: {recommend}"
            
            raise Exception(f"é˜¿é‡Œäº‘è¯•å·åˆ‡é¢˜è¯†åˆ«å¤±è´¥: {error_msg}")


async def recognize_paper_cut(
    image_url: Optional[str] = None,
    image_base64: Optional[str] = None,
    cut_type: str = "question",
    image_type: str = "scan",
    subject: str = "Math",
) -> Dict[str, Any]:
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ OCR è¯†åˆ«è¯•å·å¹¶åˆ‡é¢˜
    
    è¿™æ˜¯ä¾¿æ·å‡½æ•°ï¼Œå†…éƒ¨åˆ›å»ºå®¢æˆ·ç«¯å¹¶è°ƒç”¨ API
    
    Args:
        image_url: å›¾ç‰‡ URL
        image_base64: å›¾ç‰‡ base64 ç¼–ç 
        cut_type: åˆ‡é¢˜ç±»å‹ï¼Œquestion(åˆ‡é¢˜) / answer(åˆ‡ç­”æ¡ˆ)
        image_type: å›¾ç‰‡ç±»å‹ï¼Œscan(æ‰«æä»¶) / photo(å®æ‹å›¾)
        subject: å­¦ç§‘ç±»å‹
    
    Returns:
        åŸå§‹ API å“åº”æ•°æ®
    """
    client = AliyunPaperCutClient()
    return await client.recognize_paper_cut(
        image_url=image_url,
        image_base64=image_base64,
        cut_type=cut_type,
        image_type=image_type,
        subject=subject,
    )


def parse_question_from_paper_cut(
    subject_data: Dict[str, Any],
    page_width: int = 0,
    page_height: int = 0,
) -> Dict[str, Any]:
    """
    å°† PaperCut API è¿”å›çš„å•ä¸ªé¢˜ç›®æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†çš„ Problem æ ¼å¼
    
    Args:
        subject_data: PaperCut è¿”å›çš„å•ä¸ªé¢˜ç›®æ•°æ®
        page_width: é¡µé¢å®½åº¦
        page_height: é¡µé¢é«˜åº¦
        
    Returns:
        æ ‡å‡†åŒ–çš„é¢˜ç›®æ•°æ®ï¼š
        {
            "index": é¢˜å·,
            "type": é¢˜å‹ï¼ˆchoice/fill/short_answer ç­‰ï¼‰,
            "question": é¢˜å¹²,
            "options": é€‰é¡¹åˆ—è¡¨,
            "position": é¢˜ç›®åæ ‡,
            "text": åŸå§‹å®Œæ•´æ–‡æœ¬,
            "words_info": è¯çº§åˆ«ä¿¡æ¯,
            "has_formula": æ˜¯å¦åŒ…å«å…¬å¼
        }
    
    ç¤ºä¾‹è¾“å…¥:
        {
            "ids": ["1"],
            "text": "1.(1+5i)içš„è™šéƒ¨ä¸º A.-1 B.0 C.1 D.6",
            "prism_wordsInfo": [...]
        }
    
    ç¤ºä¾‹è¾“å‡º:
        {
            "index": 1,
            "type": "choice",
            "question": "(1+5i)içš„è™šéƒ¨ä¸º",
            "options": ["A.-1", "B.0", "C.1", "D.6"],
            ...
        }
    """
    # è·å–é¢˜å·
    ids = subject_data.get("ids", [])
    index = int(ids[0]) if ids else 0
    
    # è·å–å®Œæ•´æ–‡æœ¬
    full_text = subject_data.get("text", "").strip()
    
    # è·å–è¯çº§åˆ«ä¿¡æ¯
    words_info = subject_data.get("prism_wordsInfo", [])
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¼ï¼ˆrecClassify=51 è¡¨ç¤ºå…¬å¼ï¼‰
    has_formula = any(w.get("recClassify") == 51 for w in words_info)
    
    # è·å–é¢˜ç›®åæ ‡
    content_list_info = subject_data.get("content_list_info", [])
    position = content_list_info[0].get("pos", []) if content_list_info else []
    
    # è§£æé¢˜å¹²å’Œé€‰é¡¹
    question_text, options, question_type = extract_question_and_options(full_text, words_info)
    
    return {
        "index": index,
        "type": question_type,
        "question": question_text,
        "options": options,
        "position": position,
        "text": full_text,
        "words_info": words_info,
        "has_formula": has_formula,
        "raw_data": subject_data,
    }


def extract_question_and_options(
    full_text: str,
    words_info: List[Dict[str, Any]] = None,
) -> tuple:
    """
    ä»å®Œæ•´æ–‡æœ¬ä¸­æå–é¢˜å¹²å’Œé€‰é¡¹
    
    Args:
        full_text: å®Œæ•´çš„é¢˜ç›®æ–‡æœ¬
        words_info: è¯çº§åˆ«ä¿¡æ¯ï¼ˆç”¨äºæ›´ç²¾ç¡®çš„åˆ†å‰²ï¼‰
    
    Returns:
        (question_text, options, question_type)
    
    ç¤ºä¾‹:
        è¾“å…¥: "1.(1+5i)içš„è™šéƒ¨ä¸º A.-1 B.0 C.1 D.6"
        è¾“å‡º: ("(1+5i)içš„è™šéƒ¨ä¸º", ["A.-1", "B.0", "C.1", "D.6"], "choice")
    
    å…³é”®é€»è¾‘ï¼š
        - é€‰é¡¹æ ¼å¼å¿…é¡»æ˜¯ "A." æˆ– "Aã€" åé¢è·Ÿå†…å®¹
        - å…¬å¼ä¸­çš„å­—æ¯ï¼ˆå¦‚ $$A$$ï¼‰ä¸æ˜¯é€‰é¡¹
        - é€‰é¡¹é€šå¸¸åœ¨é¢˜ç›®æœ«å°¾ï¼ŒæŒ‰ A B C D é¡ºåºå‡ºç°
    """
    if not full_text:
        return "", [], "short_answer"
    
    # å»æ‰é¢˜å·å‰ç¼€ï¼ˆå¦‚ "1." "2." ç­‰ï¼‰
    text = re.sub(r'^\d+[.ã€ï¼]\s*', '', full_text.strip())
    
    # æ–¹æ³•1: ä½¿ç”¨ words_info ä¸­çš„é€‰é¡¹ä¿¡æ¯ï¼ˆæ›´å‡†ç¡®ï¼‰
    if words_info:
        options_from_words = extract_options_from_words_info(words_info)
        if len(options_from_words) >= 2:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªé€‰é¡¹åœ¨åŸæ–‡ä¸­çš„ä½ç½®
            first_option = options_from_words[0]
            # æŸ¥æ‰¾é€‰é¡¹åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®ï¼ˆè€ƒè™‘é€‰é¡¹å¯èƒ½ä»¥ A. Aã€$$A. å¼€å¤´ï¼‰
            first_pos = find_option_position(text, first_option)
            if first_pos >= 0:
                question_text = text[:first_pos].strip()
                return question_text, options_from_words, "choice"
    
    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ ‡å‡†é€‰é¡¹æ ¼å¼
    # æ›´ä¸¥æ ¼çš„é€‰é¡¹åŒ¹é…ï¼šå¿…é¡»æ˜¯ç‹¬ç«‹çš„ A. B. C. D.ï¼ˆä¸åœ¨å…¬å¼å†…ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼šè¡Œé¦–æˆ–ç©ºæ ¼åçš„ A. Aã€Aï¼æˆ– $$A . ï¼ˆå…¬å¼æ ¼å¼çš„é€‰é¡¹ï¼‰
    option_pattern = r'(?:^|\s)(\$\$[A-D]\s*[.ã€ï¼]|\s[A-D][.ã€ï¼])'
    
    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„é€‰é¡¹èµ·å§‹ä½ç½®
    matches = list(re.finditer(option_pattern, text))
    
    # è¿‡æ»¤ï¼šç¡®ä¿ A B C D æŒ‰é¡ºåºå‡ºç°
    valid_options = []
    expected_letters = ['A', 'B', 'C', 'D']
    letter_idx = 0
    
    for match in matches:
        matched_text = match.group(1).strip()
        # æå–å­—æ¯
        letter = re.search(r'[A-D]', matched_text)
        if letter:
            letter = letter.group()
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœŸæœ›çš„ä¸‹ä¸€ä¸ªå­—æ¯
            if letter_idx < len(expected_letters) and letter == expected_letters[letter_idx]:
                valid_options.append(match)
                letter_idx += 1
    
    if len(valid_options) >= 2:
        # è¿™æ˜¯é€‰æ‹©é¢˜
        first_option_pos = valid_options[0].start()
        question_text = text[:first_option_pos].strip()
        
        # æå–é€‰é¡¹å†…å®¹
        options = []
        for i, match in enumerate(valid_options):
            start = match.start()
            end = valid_options[i + 1].start() if i + 1 < len(valid_options) else len(text)
            option_text = text[start:end].strip()
            if option_text:
                options.append(option_text)
        
        return question_text, options, "choice"
    
    # æ–¹æ³•3: å°è¯•æ›´å®½æ¾çš„åŒ¹é…ï¼ˆç”¨äºå¤„ç†ç‰¹æ®Šæ ¼å¼ï¼‰
    # æŸ¥æ‰¾æœ«å°¾çš„é€‰é¡¹å—ï¼ˆå¦‚ "A.è½»é£ B.å¾®é£ C.å’Œé£ D.åŠ²é£"ï¼‰
    tail_options = extract_tail_options(text)
    if tail_options:
        # æ‰¾åˆ°é€‰é¡¹å—çš„èµ·å§‹ä½ç½®
        first_opt = tail_options[0]
        pos = text.rfind(first_opt)
        if pos > 0:
            question_text = text[:pos].strip()
            return question_text, tail_options, "choice"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¡«ç©ºé¢˜ï¼ˆåŒ…å«ä¸‹åˆ’çº¿æˆ–ç©ºæ ¼å¡«ç©ºæ ‡è®°ï¼‰
    if "___" in text or "____" in text or re.search(r'_{3,}', text):
        return text, [], "fill"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯è¯æ˜é¢˜
    if any(kw in text for kw in ["è¯æ˜", "æ±‚è¯", "è¯•è¯"]):
        return text, [], "proof"
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯è§£ç­”é¢˜
    if any(kw in text for kw in ["è®¡ç®—", "æ±‚", "è§£", "è§£ç­”"]):
        return text, [], "solve"
    
    # é»˜è®¤ä¸ºç®€ç­”é¢˜
    return text, [], "short_answer"


def extract_options_from_words_info(words_info: List[Dict[str, Any]]) -> List[str]:
    """
    ä»è¯çº§åˆ«ä¿¡æ¯ä¸­æå–é€‰é¡¹
    
    é€šè¿‡ recClassify å’Œ word å†…å®¹åˆ¤æ–­å“ªäº›æ˜¯é€‰é¡¹
    
    Args:
        words_info: è¯çº§åˆ«ä¿¡æ¯åˆ—è¡¨
    
    Returns:
        é€‰é¡¹åˆ—è¡¨ï¼Œå¦‚ ["A.-1", "B.0", "C.1", "D.6"]
    """
    options = []
    expected_letters = ['A', 'B', 'C', 'D']
    letter_idx = 0
    
    for word_info in words_info:
        word = word_info.get("word", "")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€‰é¡¹å¼€å¤´
        # æ ‡å‡†æ ¼å¼: A. Aã€Aï¼æˆ– $$A .ï¼ˆå…¬å¼æ ¼å¼ï¼‰
        if letter_idx < len(expected_letters):
            expected = expected_letters[letter_idx]
            
            # æ£€æŸ¥å„ç§é€‰é¡¹æ ¼å¼
            is_option = False
            if word.startswith(f"{expected}.") or word.startswith(f"{expected}ã€"):
                is_option = True
            elif word.startswith(f"$${expected}") or word.startswith(f"$${ expected}"):
                is_option = True
            elif word.strip() == f"{expected}." or word.strip() == f"{expected}ã€":
                is_option = True
            
            if is_option:
                options.append(word.strip())
                letter_idx += 1
    
    return options


def find_option_position(text: str, option: str) -> int:
    """
    åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°é€‰é¡¹çš„ä½ç½®
    
    Args:
        text: å®Œæ•´æ–‡æœ¬
        option: é€‰é¡¹æ–‡æœ¬
    
    Returns:
        é€‰é¡¹åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› -1
    """
    # ç›´æ¥æŸ¥æ‰¾
    pos = text.find(option)
    if pos >= 0:
        return pos
    
    # å°è¯•æŸ¥æ‰¾é€‰é¡¹çš„å¼€å¤´éƒ¨åˆ†ï¼ˆå¦‚ "A." "Aã€"ï¼‰
    for pattern in [r'[A-D][.ã€ï¼]', r'\$\$[A-D]']:
        match = re.search(pattern, option)
        if match:
            prefix = match.group()
            pos = text.find(prefix)
            if pos >= 0:
                return pos
    
    return -1


def extract_tail_options(text: str) -> List[str]:
    """
    ä»æ–‡æœ¬æœ«å°¾æå–é€‰é¡¹ï¼ˆç”¨äºå¤„ç†é€‰é¡¹åœ¨æœ€åçš„æƒ…å†µï¼‰
    
    Args:
        text: å®Œæ•´æ–‡æœ¬
    
    Returns:
        é€‰é¡¹åˆ—è¡¨
    """
    # åŒ¹é…æœ«å°¾çš„é€‰é¡¹å—
    # æ ¼å¼ï¼šA.xxx B.xxx C.xxx D.xxx
    pattern = r'([A-D][.ã€ï¼][^\s]*(?:\s|$))'
    
    # ä»åå¾€å‰æŸ¥æ‰¾
    matches = list(re.finditer(pattern, text))
    
    if len(matches) >= 2:
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç»­çš„ A B C D
        options = []
        expected = ['A', 'B', 'C', 'D']
        
        for match in matches:
            opt_text = match.group(1).strip()
            letter = opt_text[0] if opt_text else ''
            
            if letter in expected:
                idx = expected.index(letter)
                # ç¡®ä¿æŒ‰é¡ºåº
                if len(options) == idx:
                    options.append(opt_text)
        
        if len(options) >= 2:
            return options
    
    return []


def parse_paper_cut_response(
    response_data: Dict[str, Any],
) -> Dict[str, Any]:
    """
    è§£æ PaperCut API çš„å®Œæ•´å“åº”ï¼Œè½¬æ¢ä¸ºæ ‡å‡†çš„è¯•å·ç»“æ„
    
    Args:
        response_data: PaperCut API çš„åŸå§‹å“åº”
    
    Returns:
        æ ‡å‡†åŒ–çš„è¯•å·æ•°æ®ï¼š
        {
            "page_count": é¡µé¢æ•°é‡,
            "total_questions": é¢˜ç›®æ€»æ•°,
            "pages": [
                {
                    "page_id": é¡µç ,
                    "width": å®½åº¦,
                    "height": é«˜åº¦,
                    "questions": [æ ‡å‡†åŒ–çš„é¢˜ç›®åˆ—è¡¨]
                }
            ]
        }
    """
    pages = []
    total_questions = 0
    
    for page_data in response_data.get("page_list", []):
        page_id = page_data.get("page_id", 0)
        width = page_data.get("width", 0)
        height = page_data.get("height", 0)
        
        questions = []
        for subject in page_data.get("subject_list", []):
            parsed = parse_question_from_paper_cut(subject, width, height)
            questions.append(parsed)
            total_questions += 1
        
        pages.append({
            "page_id": page_id,
            "width": width,
            "height": height,
            "questions": questions,
        })
    
    return {
        "page_count": len(pages),
        "total_questions": total_questions,
        "pages": pages,
    }


def convert_to_parsed_questions(
    response_data: Dict[str, Any],
    image_url: Optional[str] = None,
    image_base64: Optional[str] = None,
) -> List[Dict[str, Any]]:
    """
    å°† PaperCut API å“åº”è½¬æ¢ä¸º ParsedQuestion å…¼å®¹çš„æ ¼å¼
    
    è¿™æ˜¯ä¸»è¦çš„è½¬æ¢å‡½æ•°ï¼Œç”¨äºå°† PaperCut çš„ç»“æœæ¥å…¥ç°æœ‰çš„è¯Šæ–­æµç¨‹
    
    Args:
        response_data: PaperCut API çš„åŸå§‹å“åº”
        image_url: åŸå§‹å›¾ç‰‡ URLï¼ˆç”¨äºåç»­è¯Šæ–­ï¼‰
        image_base64: åŸå§‹å›¾ç‰‡ base64ï¼ˆç”¨äºåç»­è¯Šæ–­ï¼‰
    
    Returns:
        ParsedQuestion å…¼å®¹çš„é¢˜ç›®åˆ—è¡¨
    """
    questions = []
    
    for page_data in response_data.get("page_list", []):
        page_width = page_data.get("width", 0)
        page_height = page_data.get("height", 0)
        
        for subject in page_data.get("subject_list", []):
            parsed = parse_question_from_paper_cut(subject, page_width, page_height)
            
            # è½¬æ¢ä¸º ParsedQuestion å…¼å®¹æ ¼å¼
            question = {
                "index": parsed["index"],
                "type": parsed["type"],
                "question": parsed["question"],
                "options": parsed["options"] if parsed["options"] else None,
                "position": parsed["position"],
                "section_title": "",  # PaperCut ä¸è¿”å›å¤§é¢˜åˆ†ç±»
                "elements": None,     # PaperCut ä¸è¿”å›å…ƒç´ åˆ—è¡¨
                "figures": [],        # éœ€è¦ä» words_info ä¸­æå–
                "has_figure": False,  # åç»­å¯ä»¥æ ¹æ®éœ€è¦æ£€æµ‹
                "figure_description": None,
                "knowledge_points": [],  # ç”±è¯Šæ–­å¼•æ“å¡«å……
                "difficulty": None,      # ç”±è¯Šæ–­å¼•æ“å¡«å……
                "image_url": image_url,
                "image_base64": image_base64,
                "raw_text": parsed["text"],
                "has_formula": parsed["has_formula"],
            }
            
            questions.append(question)
    
    return questions


async def recognize_and_parse_paper(
    image_url: Optional[str] = None,
    image_base64: Optional[str] = None,
    cut_type: str = "question",
    image_type: str = "scan",
    subject: str = "Math",
) -> tuple:
    """
    è¯†åˆ«å¹¶è§£æè¯•å·ï¼ˆé«˜çº§æ¥å£ï¼‰
    
    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·å‡½æ•°ï¼Œæ•´åˆäº† API è°ƒç”¨å’Œç»“æœè§£æ
    
    Args:
        image_url: å›¾ç‰‡ URL
        image_base64: å›¾ç‰‡ base64 ç¼–ç 
        cut_type: åˆ‡é¢˜ç±»å‹
        image_type: å›¾ç‰‡ç±»å‹
        subject: å­¦ç§‘ç±»å‹
    
    Returns:
        (raw_data, parsed_questions): åŸå§‹æ•°æ®å’Œè§£æåçš„é¢˜ç›®åˆ—è¡¨
    
    ç¤ºä¾‹:
        raw_data, questions = await recognize_and_parse_paper(image_base64=img_b64)
        for q in questions:
            print(f"é¢˜ç›® {q['index']}: {q['type']} - {q['question'][:50]}...")
    """
    print("\n" + "=" * 80)
    print("ğŸ”ª è¯•å·åˆ‡é¢˜è¯†åˆ«å¼€å§‹ (PaperCut)...")
    print("=" * 80)
    
    # è°ƒç”¨ API
    raw_data = await recognize_paper_cut(
        image_url=image_url,
        image_base64=image_base64,
        cut_type=cut_type,
        image_type=image_type,
        subject=subject,
    )
    
    # è§£æç»“æœ
    questions = convert_to_parsed_questions(
        raw_data,
        image_url=image_url,
        image_base64=image_base64,
    )
    
    print(f"\nâœ… è¯†åˆ«å®Œæˆï¼Œå…±è§£æ {len(questions)} é“é¢˜ç›®")
    for q in questions:
        opt_info = f" ({len(q['options'])}é€‰é¡¹)" if q['options'] else ""
        formula_info = " ğŸ“" if q.get('has_formula') else ""
        print(f"   [{q['index']}] {q['type']}{opt_info}{formula_info}: {q['question'][:40]}...")
    
    print("=" * 80 + "\n")
    
    return raw_data, questions
