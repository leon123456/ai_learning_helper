#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜è€ƒè¯•å·è¯†åˆ«æµ‹è¯• - ç®€åŒ–ç‰ˆ

ä¸“é—¨ç”¨äºæµ‹è¯• test_png ç›®å½•ä¸‹çš„ 2025 é«˜è€ƒè¯•å·å›¾ç‰‡

ä½¿ç”¨æ–¹å¼ï¼š
    python test/test_gaokao_paper.py
    
    æˆ–è€…ä»ä»»æ„ç›®å½•è¿è¡Œï¼š
    python /path/to/test_gaokao_paper.py
"""

import sys
import asyncio
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

import base64

# æ£€æŸ¥é˜¿é‡Œäº‘é…ç½®
from app.core.config import settings

def check_aliyun_config():
    """æ£€æŸ¥é˜¿é‡Œäº‘é…ç½®æ˜¯å¦å®Œæ•´"""
    if not settings.ALIYUN_ACCESS_KEY_ID or not settings.ALIYUN_ACCESS_KEY_SECRET:
        print("\n" + "="*80)
        print("âŒ é˜¿é‡Œäº‘ OCR é…ç½®ä¸å®Œæ•´ï¼")
        print("="*80)
        print("\nè¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š\n")
        print("# é˜¿é‡Œäº‘ OCR é…ç½®")
        print("ALIYUN_ACCESS_KEY_ID=ä½ çš„AccessKeyId")
        print("ALIYUN_ACCESS_KEY_SECRET=ä½ çš„AccessKeySecret")
        print("ALIYUN_OCR_ENDPOINT=cn-hangzhou.aliyuncs.com")
        print("\nè·å– AccessKey: https://ram.console.aliyun.com/manage/ak")
        print("ç¡®ä¿ RAM æƒé™: AliyunOCRFullAccess æˆ– AliyunOCRReadOnlyAccess")
        print("="*80 + "\n")
        return False
    
    print(f"âœ… é˜¿é‡Œäº‘é…ç½®å·²åŠ è½½ (AccessKey ID: {settings.ALIYUN_ACCESS_KEY_ID[:8]}...)")
    return True


async def test_gaokao_paper():
    """æµ‹è¯•é«˜è€ƒè¯•å·è¯†åˆ«"""
    
    print("\n" + "="*80)
    print("ğŸ“„ 2025 é«˜è€ƒè¯•å·è¯†åˆ«æµ‹è¯•")
    print("="*80)
    
    # æ£€æŸ¥é…ç½®
    if not check_aliyun_config():
        return
    
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„
    test_dir = Path(__file__).parent / "test_png"
    images = sorted(test_dir.glob("*.png"))
    
    if not images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    print(f"\nå‘ç° {len(images)} å¼ æµ‹è¯•å›¾ç‰‡:")
    for img in images:
        print(f"  - {img.name}")
    
    # æµ‹è¯•æ¯å¼ å›¾ç‰‡
    all_results = []
    
    for i, image_path in enumerate(images, 1):
        print(f"\n{'='*80}")
        print(f"[{i}/{len(images)}] æµ‹è¯•: {image_path.name}")
        print("="*80)
        
        try:
            # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
            print("ğŸ“¦ è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64...")
            with open(image_path, "rb") as f:
                image_base64 = base64.b64encode(f.read()).decode("utf-8")
            
            print(f"   å›¾ç‰‡å¤§å°: {len(image_base64)} å­—ç¬¦")
            
            # è°ƒç”¨è¯†åˆ«æœåŠ¡ï¼ˆç›´æ¥ä½¿ç”¨é˜¿é‡Œäº‘ OCRï¼Œä¸éœ€è¦ LLMï¼‰
            print("ğŸ” è°ƒç”¨é˜¿é‡Œäº‘è¯•å·è¯†åˆ« API...")
            import time
            start_time = time.time()
            
            # å¯¼å…¥é˜¿é‡Œäº‘è¯•å· OCR æœåŠ¡
            from app.services.aliyun_paper_ocr import (
                recognize_paper_structure, 
                parse_question_from_aliyun,
                merge_question_with_options,
            )
            from app.schemas.paper import ParsedQuestion
            
            # è°ƒç”¨é˜¿é‡Œäº‘ API
            raw_data = await recognize_paper_structure(image_base64=image_base64)
            
            # æ„å»º PaperStructure
            from app.schemas.paper import PaperStructure
            paper_structure = PaperStructure(
                page_id=raw_data.get("page_id", 0),
                page_title=raw_data.get("page_title", ""),
                width=raw_data.get("width", 0),
                height=raw_data.get("height", 0),
                part_info=[],
                figure=raw_data.get("figure", []),
                raw_data=raw_data
            )
            
            # è·å–æ‰€æœ‰é…å›¾å’Œé¡µé¢é«˜åº¦
            all_figures = raw_data.get("figure", [])
            page_height = raw_data.get("height", 0)
            
            # ç¬¬ä¸€æ­¥ï¼šè§£ææ‰€æœ‰é¢˜ç›®ï¼ˆå…³è”é…å›¾ï¼‰
            parsed_questions_raw = []
            for part in raw_data.get("part_info", []):
                section_title = part.get("part_title", "")
                for subject in part.get("subject_list", []):
                    # ä¼ é€’é…å›¾åˆ—è¡¨ï¼Œè®©è§£æå‡½æ•°è‡ªåŠ¨å…³è”
                    parsed = parse_question_from_aliyun(
                        subject, 
                        all_figures=all_figures,
                        page_height=page_height
                    )
                    parsed["section_title"] = section_title
                    parsed_questions_raw.append(parsed)
            
            # ç¬¬äºŒæ­¥ï¼šåˆå¹¶è¢«é”™è¯¯åˆ†å‰²çš„é¢˜ç›®å’Œé€‰é¡¹
            print("ğŸ”§ æ£€æŸ¥å¹¶åˆå¹¶åˆ†å‰²çš„é¢˜ç›®...")
            parsed_questions_merged = merge_question_with_options(parsed_questions_raw)
            
            # ç¬¬ä¸‰æ­¥ï¼šè½¬æ¢ä¸º ParsedQuestion å¯¹è±¡
            questions = []
            for parsed in parsed_questions_merged:
                question = ParsedQuestion(
                    index=parsed["index"],
                    type=parsed["type"],
                    question=parsed["question"],
                    options=parsed["options"],
                    position=parsed["position"],
                    section_title=parsed.get("section_title", ""),
                    elements=parsed.get("elements"),
                    figures=parsed.get("figures", []),
                    has_figure=parsed.get("has_figure", False),
                    figure_description=parsed.get("figure_description"),
                )
                questions.append(question)
            
            recognition_time = time.time() - start_time
            
            # è®°å½•ç»“æœ
            result = {
                "image_name": image_path.name,
                "status": "success",
                "recognition_time": recognition_time,
                "total_questions": len(questions),
                "paper_info": {
                    "page_id": paper_structure.page_id,
                    "width": paper_structure.width,
                    "height": paper_structure.height,
                    "sections": []
                },
                "questions": [],
                "figures": raw_data.get("figure", []),  # ä¿å­˜å›¾ç‰‡/å›¾å½¢åæ ‡ä¿¡æ¯
            }
            
            # ç»Ÿè®¡å¤§é¢˜ä¿¡æ¯
            for section in paper_structure.part_info:
                result["paper_info"]["sections"].append({
                    "title": section.part_title,
                    "count": len(section.subject_list)
                })
            
            # è®°å½•é¢˜ç›®ä¿¡æ¯
            for q in questions:
                # å°† PaperFigure å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
                figures_dict = []
                for fig in q.figures:
                    if hasattr(fig, 'model_dump'):
                        figures_dict.append(fig.model_dump())
                    elif hasattr(fig, 'dict'):
                        figures_dict.append(fig.dict())
                    elif isinstance(fig, dict):
                        figures_dict.append(fig)
                    else:
                        figures_dict.append(str(fig))
                
                result["questions"].append({
                    "index": q.index,
                    "type": q.type,
                    "section_title": q.section_title,
                    "question": q.question,
                    "options": q.options,
                    "has_position": bool(q.position),
                    "has_figure": q.has_figure,
                    "figure_count": len(q.figures),
                    "figure_description": q.figure_description,
                    "figures": figures_dict,  # ä¿å­˜å®Œæ•´çš„é…å›¾ä¿¡æ¯
                })
            
            all_results.append(result)
            
            # æ‰“å°ç»“æœ
            print(f"\nâœ… è¯†åˆ«æˆåŠŸ!")
            print(f"  â±ï¸  è€—æ—¶: {recognition_time:.2f} ç§’")
            print(f"  ğŸ“ å›¾ç‰‡å°ºå¯¸: {paper_structure.width} x {paper_structure.height}")
            print(f"  ğŸ“Š è¯†åˆ«åˆ° {len(questions)} é“é¢˜ç›®")
            
            if paper_structure.part_info:
                print(f"\n  ğŸ“‹ å¤§é¢˜åˆ†åŒº:")
                for section in paper_structure.part_info:
                    print(f"     - {section.part_title}: {len(section.subject_list)} é“é¢˜")
            
            print(f"\n  ğŸ“ é¢˜ç›®è¯¦æƒ…:")
            for j, q in enumerate(questions[:10], 1):  # åªæ˜¾ç¤ºå‰10é¢˜
                preview = q.question[:80] + "..." if len(q.question) > 80 else q.question
                options_info = f"ï¼ˆ{len(q.options)} ä¸ªé€‰é¡¹ï¼‰" if q.options else ""
                figure_info = f" ğŸ–¼ï¸{len(q.figures)}å›¾" if q.has_figure else ""
                print(f"     {q.index}. [{q.type}] {preview} {options_info}{figure_info}")
            
            if len(questions) > 10:
                print(f"     ... è¿˜æœ‰ {len(questions) - 10} é“é¢˜ç›®")
            
            # æ‰“å°å›¾ç‰‡/å›¾å½¢ä¿¡æ¯
            figures = raw_data.get("figure", [])
            if figures:
                print(f"\n  ğŸ–¼ï¸  è¯†åˆ«åˆ° {len(figures)} ä¸ªå›¾ç‰‡/å›¾å½¢:")
                for fig in figures[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    fig_type = fig.get("type", "unknown")
                    x, y = fig.get("x", 0), fig.get("y", 0)
                    w, h = fig.get("w", 0), fig.get("h", 0)
                    print(f"     - ç±»å‹: {fig_type}, ä½ç½®: ({x}, {y}), å°ºå¯¸: {w}x{h}")
                if len(figures) > 5:
                    print(f"     ... è¿˜æœ‰ {len(figures) - 5} ä¸ªå›¾å½¢")
            else:
                print(f"\n  ğŸ–¼ï¸  æœªè¯†åˆ«åˆ°é¢˜ç›®é…å›¾")
            
        except Exception as e:
            print(f"\nâŒ è¯†åˆ«å¤±è´¥")
            print(f"  é”™è¯¯: {e}")
            
            import traceback
            traceback.print_exc()
            
            result = {
                "image_name": image_path.name,
                "status": "failed",
                "error": str(e),
            }
            all_results.append(result)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*80}")
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»")
    print("="*80)
    
    success_count = sum(1 for r in all_results if r["status"] == "success")
    total_questions = sum(r.get("total_questions", 0) for r in all_results)
    
    print(f"æµ‹è¯•å›¾ç‰‡æ•°: {len(all_results)}")
    print(f"æˆåŠŸ: {success_count}")
    print(f"å¤±è´¥: {len(all_results) - success_count}")
    print(f"è¯†åˆ«é¢˜ç›®æ€»æ•°: {total_questions}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_dir = Path(__file__).parent / "test_results"
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"gaokao_test_{timestamp}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "test_time": datetime.now().isoformat(),
            "test_images": [img.name for img in images],
            "results": all_results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜: {output_file}")
    print("="*80 + "\n")


if __name__ == "__main__":
    asyncio.run(test_gaokao_paper())

